{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,Callback\n\n\nfrom tensorflow.keras.optimizers import Adam\nimport keras\nimport tensorflow as tf\nfrom keras import backend as k\nfrom tensorflow.keras.layers import Activation, Dense, Dropout, Conv2D, \\\n                         Flatten, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,ProgbarLogger\nfrom sklearn.model_selection import train_test_split\nimport librosa\nimport librosa.display\nimport numpy as np\nimport pandas as pd\nimport random\nimport warnings\nimport matplotlib.pyplot as plt, os\nwarnings.filterwarnings('ignore')\n\n#object serialization\nimport _pickle as cPickle  #python 3 change\nimport os  \n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/freesound-audio-tagging-2019/train_curated.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tqdm as tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport librosa\n\nlabel = pd.read_csv(r'C:\\Users\\Ramstein\\Documents\\SmartsuitStudioProjects\\Sample project\\Export\\scene-1\\SuddenCrouch_HUMANIK_E46.csv')\ndf = label.drop(['Timestamp'], axis=1)\ndfn = df.to_numpy().astype(np.float32)\nprint(dfn.shape)\nnp.save('label.npy', dfn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tqdm as tqdm\nimport pandas as pd\nimport numpy as np\nimport os\nimport librosa\n\ndef data_to_spec(data):\n    d = librosa.stft(data)   # wav to short-term-fourier-transform\n    return librosa.power_to_db(np.abs(d)**2, ref=np.median)\n\ndef file_to_spec(filename, i):\n    y, sr = librosa.load(filename,sr=16000, offset=(0.03333333333)*i, duration=0.03333333333)\n    print(sr)\n    return data_to_spec(y)\n\nPath = r'C:\\Conv\\wavs'\n# files = os.listdir(path)\nfiles=['Conv12.wav']\narr = []\n\nfor file in tqdm.tqdm(files):\n    file = os.path.join(Path, file)\n    duration = librosa.core.get_duration(filename=file) \n    print('duration:', duration )\n    Slice=int((duration*1000)//33.3333333333)\n\n    for i in range(Slice):\n        try:\n            d = file_to_spec(file, i)\n            d = d.transpose()\n        except Exception as e:print(e);continue\n        arr.append(d)\n    break\n\ndata_n = np.array(arr) /255\nprint(data_n.shape)\n# np.save('train.npy', data_n[:652])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = pd.read_csv('../input/motion-sudden-crouch/SuddenCrouch_HUMANIK_E46.csv')\ndf = label.drop(['Timestamp'], axis=1)\ndf.head()\n# lanel reshaping and converting into the classes\ndfn = df.to_numpy().astype(np.float16)\ndfn = dfn[:-1]\nprint(dfn.shape, dfn[0].shape)  #dfn.shape=(651, 441) where 651 is total number of samples\n                                # and 441 is number of classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sr = 16000\n# for i, file in enumerate(files):\n# if i==20: break    \nfname = os.path.join('/kaggle/working', files[14])   # Hi-hat\nwav, _ = librosa.core.load(fname)\n\nwav = wav[:330]\n#display waveform\n\n#     plt.figure(figsize=(14, 5))\n#     librosa.display.waveplot(wav, sr=sr)\n\n\n#display Spectrogram\nX = librosa.stft(wav)\nXdb = librosa.amplitude_to_db(abs(X))\nprint(Xdb)\nplt.figure(figsize=(14, 5))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz') \n#If to pring log of frequencies  \n#librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\nplt.colorbar()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = np.load('/kaggle/input/audio-mfcc-test/train.npy')\n# dfn = np.load('/kaggle/input/audio-mfcc-test/label.npy')\n\n\n# #split up test into test and validation \n# X_train, X_val, y_train, y_val = train_test_split(train, dfn, test_size=0.30, random_state=42)\n\n# X_train  = X_train.reshape(X_train.shape[0], 33, 1025, 1)\n# X_val  = X_val.reshape(X_val.shape[0], 33, 1025, 1)\n\n\n# X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.40, random_state=42)\n\n# print (\"test \",X_train.shape, len(y_train))\n# print (\"valid \", X_val.shape, len(y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\nimport math\nimport string, random, time\n\nimport tensorflow as tf\nfrom six.moves import xrange\nfrom tensorflow.keras import backend as backend\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom tensorflow.keras.layers import Dense, Reshape, Input\nfrom tensorflow.keras.layers import multiply, add\nfrom tensorflow.keras.models import Model\n\nBlockArgs = collections.namedtuple('BlockArgs', [\n    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n    'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n])\nBlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\nDEFAULT_BLOCKS_ARGS = [\n    BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n              expand_ratio=1, id_skip=True, strides=1, se_ratio=0.25),\n    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n              expand_ratio=6, id_skip=True, strides=1, se_ratio=0.25),\n    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n              expand_ratio=6, id_skip=True, strides=2, se_ratio=0.25),\n    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n              expand_ratio=6, id_skip=True, strides=1, se_ratio=0.25)\n]\n\nCONV_KERNEL_INITIALIZER = {\n    'class_name': 'VarianceScaling',\n    'config': {\n        'scale': 2.0,\n        'mode': 'fan_out',\n        # EfficientNet1D actually uses an untruncated normal distribution for\n        # initializing conv layers, but keras.initializers.VarianceScaling use\n        # a truncated distribution.\n        # We decided against a custom initializer for better serializability.\n        'distribution': 'normal'\n    }\n}\nDENSE_KERNEL_INITIALIZER = {\n    'class_name': 'VarianceScaling',\n    'config': {\n        'scale': 1. / 3.,\n        'mode': 'fan_out',\n        'distribution': 'uniform'\n    }\n}\n\n\ndef round_filters(filters, width_coefficient, depth_divisor):\n    \"\"\"Round number of filters based on width multiplier.\"\"\"\n    filters *= width_coefficient\n    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n    new_filters = max(depth_divisor, new_filters)\n    # Make sure that round down does not go down by more than 10%.\n    if new_filters < 0.9 * filters:\n        new_filters += depth_divisor\n    return int(new_filters)\n\n\ndef get_swish(**kwargs):\n    def swish(x):\n        \"\"\"Swish activation function: x * sigmoid(x).\n        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n        \"\"\"\n        if backend.backend() == 'tensorflow':\n            try:\n                # The native TF implementation has a more\n                # memory-efficient gradient implementation\n                return tf.nn.swish(x)\n            except AttributeError:\n                pass\n        return x * backend.sigmoid(x)\n\n    return swish\n\n\ndef round_repeats(repeats, depth_coefficient):\n    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n    return int(math.ceil(depth_coefficient * repeats))\n\n\ndef get_dropout(**kwargs):\n    \"\"\"Wrapper over custom dropout. Fix problem of ``None`` shape for tf.keras.\n    It is not possible to define FixedDropout class as global object,\n    because we do not have modules for inheritance at first time.\n    Issue:\n        https://github.com/tensorflow/tensorflow/issues/30946\n    \"\"\"\n\n    class FixedDropout(tf.keras.layers.Dropout):\n        def _get_noise_shape(self, inputs):\n            if self.noise_shape is None:\n                return self.noise_shape\n            symbolic_shape = backend.shape(inputs)\n            noise_shape = [symbolic_shape[axis] if shape is None else shape\n                           for axis, shape in enumerate(self.noise_shape)]\n            return tuple(noise_shape)\n\n    return FixedDropout\n\n\ndef mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', ):\n    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n    # workaround over non working dropout with None in noise_shape in tf.keras\n    Dropout = get_dropout()\n    d_num = 1\n    # expansion phase\n    filters = block_args.input_filters * block_args.expand_ratio\n    if block_args.expand_ratio != 1:\n        x = Conv1D(filters,\n                   kernel_size=1,\n                   padding='causal', use_bias=False,\n                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n                   name=prefix + 'expand_conv')(inputs)\n        x = tf.keras.layers.Dropout(rate=0.05, name='exp_dropout-{}'.format(random.randint(1, 10000)))(x);random.seed(time.clock())\n        x = Activation(activation, name=prefix + 'expand_activation-{}'.format(random.randint(1, 10000)))(x);random.seed(time.clock())\n    else:\n        x = inputs\n\n    # Depthwise Convolution\n    x = Conv1D(filters=filters,\n               kernel_size=block_args.kernel_size,\n               strides=block_args.strides,\n               padding='causal',\n               use_bias=False,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n               name=prefix + 'dw_conv')(x)\n    x = tf.keras.layers.Dropout(rate=0.05, name=prefix + 'exp_dropout-{}'.format(random.randint(1, 10000)))(x);random.seed(time.clock())\n    x = Activation(activation, name=prefix + 'expand_activation-{}'.format(random.randint(1, 10000)))(x);random.seed(time.clock())\n\n    # squeeze the excitation phase\n    if has_se:\n        num_reduced_filters = max(1, int(block_args.input_filters * block_args.se_ratio))\n        se_tensor = GlobalAveragePooling1D(name=prefix + 'se_squeeze')(x)\n\n        ###########################look here\n        target_shape = (1, filters)\n        se_tensor = Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n        se_tensor = Conv1D(filters=num_reduced_filters,\n                           kernel_size=1,\n                           activation=activation,\n                           padding='causal',\n                           use_bias=True,\n                           kernel_initializer=CONV_KERNEL_INITIALIZER,\n                           name=prefix + 'se_reduce')(se_tensor)\n        se_tensor = Conv1D(filters=filters,\n                           kernel_size=1,\n                           activation='sigmoid',\n                           padding='causal',\n                           use_bias=True,\n                           kernel_initializer=CONV_KERNEL_INITIALIZER,\n                           name=prefix + 'se_expand')(se_tensor)\n        x = multiply([x, se_tensor], name=prefix + 'se_excite')\n\n    # Output phase\n    x = Conv1D(filters=block_args.output_filters,\n               kernel_size=1,\n               padding='causal',\n               use_bias=False,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n               name=prefix + 'project_conv')(x)\n    x = tf.keras.layers.Dropout(rate=0.05, name=prefix + 'out_phase_dropout')(x)\n    if block_args.id_skip and block_args.input_filters == block_args.output_filters:\n        if drop_rate and (drop_rate > 0):\n            x = Dropout(drop_rate,\n                        noise_shape=(None, 1, 1),\n                        name=prefix + 'drop')(x)\n        x = add([x, inputs], name=prefix + 'add')\n\n    return x\n\n\ndef EfficientNet1D(width_coefficient,\n                   depth_coefficient,\n                   default_resolution,\n                   dropout_rate=0.2,\n                   drop_connect_rate=0.2,\n                   depth_divisor=8,\n                   blocks_args=DEFAULT_BLOCKS_ARGS,\n                   model_name='efficientnet',\n                   include_top=True,\n                   input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    \"\"\"Instantiates the EfficientNet1D architecture using given scaling coefficients.\n        Optionally loads weights pre-trained on ImageNet.\n        Note that the data format convention used by the model is\n        the one specified in your Keras config at `~/.keras/keras.json`.\n        # Arguments\n            width_coefficient: float, scaling coefficient for network width.\n            depth_coefficient: float, scaling coefficient for network depth.\n            default_resolution: int, default input image size.\n            dropout_rate: float, dropout rate before final classifier layer.\n            drop_connect_rate: float, dropout rate at skip connections.\n            depth_divisor: int.\n            blocks_args: A list of BlockArgs to construct block modules.\n            model_name: string, model name.\n            include_top: whether to include the fully-connected\n                layer at the top of the network.\n\n            input_shape: optional shape tuple, only to be specified\n                if `include_top` is False.\n                It should have exactly 3 inputs channels.\n            pooling: optional pooling mode for feature extraction\n                when `include_top` is `False`.\n                - `None` means that the output of the model will be\n                    the 4D tensor output of the\n                    last convolutional layer.\n                - `avg` means that global average pooling\n                    will be applied to the output of the\n                    last convolutional layer, and thus\n                    the output of the model will be a 2D tensor.\n                - `max` means that global max pooling will\n                    be applied.\n            classes: optional number of classes to classify images\n                into, only to be specified if `include_top` is True, and\n                if no `weights` argument is specified.\n        # Returns\n            A Keras model instance.\n        # Raises\n            ValueError: in case of invalid argument for `weights`,\n                or invalid input shape.\n        \"\"\"\n    activation = get_swish(**kwargs)\n    input = Input(shape=input_shape)\n    # Build stem\n    x = input\n    x = Conv1D(filters=round_filters(32, width_coefficient, depth_divisor),\n               kernel_size=3,\n               strides=2,\n               padding='causal',\n               use_bias=False,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n               name='stem_conv')(input)\n    x = tf.keras.layers.Dropout(rate=0.05, name='stem_dropout')(x)\n    x = Activation(activation, name='stem_activation', )(x)\n\n    # Build blocks\n    num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n    block_num = 0\n    for idx, block_args in enumerate(blocks_args):\n        assert block_args.num_repeat > 0\n        # Update block input and output filters based on depth multiplier.\n        block_args = block_args._replace(\n            input_filters=round_filters(block_args.input_filters,\n                                        width_coefficient, depth_divisor),\n            output_filters=round_filters(block_args.output_filters,\n                                         width_coefficient, depth_divisor),\n            num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n\n        # The first block needs to take care of stride and filter size increase.\n        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n        x = mb_conv_block(x, block_args,\n                          activation=activation,\n                          drop_rate=drop_rate,\n                          prefix='block{}a_'.format(idx + 1))\n        block_num += 1\n        if block_args.num_repeat > 1:\n            # pylint: disable=protected-access\n            block_args = block_args._replace(\n                input_filters=block_args.output_filters, strides=1)\n            # pylint: enable=protected-access\n            for bidx in xrange(block_args.num_repeat - 1):\n                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n                block_prefix = 'block{}{}_'.format(\n                    idx + 1,\n                    string.ascii_lowercase[bidx + 1]\n                )\n                x = mb_conv_block(x, block_args,\n                                  activation=activation,\n                                  drop_rate=drop_rate,\n                                  prefix=block_prefix)\n                block_num += 1\n\n    # Build top\n    x = Conv1D(round_filters(1280, width_coefficient, depth_divisor), 1,\n               padding='same',\n               use_bias=False,\n               kernel_initializer=CONV_KERNEL_INITIALIZER,\n               name='top_conv')(x)\n    x = tf.keras.layers.Dropout(rate=0.05, name='top_dropout-{}'.format(random.randint(1, 10000)))(x);random.seed(time.clock())\n    x = Activation(activation, name='top_activation')(x)\n\n    if include_top:\n        x = GlobalAveragePooling1D(name='avg_pool')(x)\n        if dropout_rate and dropout_rate > 0:\n            x = tf.keras.layers.Dropout(dropout_rate, name='top_dropout-{}'.format(random.randint(1, 10000)))(x);random.seed(time.clock())\n        x = Dense(classes,\n                  activation='softmax',\n                  kernel_initializer=DENSE_KERNEL_INITIALIZER,\n                  name='probs')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling1D(name='avg_pool')(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling1D(name='max_pool')(x)\n\n    # Create model.\n    model = Model(input, x, name=model_name)\n    return model\n\n\ndef EfficientNetB0(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(1.0, 1.0, 224, 0.2,\n                          model_name='efficientnet-b0',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n\n\ndef EfficientNetB1(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(1.0, 1.1, 240, 0.2,\n                          model_name='efficientnet-b1',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n\n\ndef EfficientNetB2(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(1.1, 1.2, 260, 0.3,\n                          model_name='efficientnet-b2',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n\n\ndef EfficientNetB3(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(1.2, 1.4, 300, 0.3,\n                          model_name='efficientnet-b3',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n\n\ndef EfficientNetB4(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(1.4, 1.8, 380, 0.4,\n                          model_name='efficientnet-b4',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n\n\ndef EfficientNetB5(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(1.6, 2.2, 456, 0.4,\n                          model_name='efficientnet-b5',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n\n\ndef EfficientNetB6(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(1.8, 2.6, 528, 0.5,\n                          model_name='efficientnet-b6',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n\n\ndef EfficientNetB7(include_top=True,input_shape=None,\n                   pooling=None,\n                   classes=1000,\n                   **kwargs):\n    return EfficientNet1D(2.0, 3.1, 600, 0.5,\n                          model_name='efficientnet-b7',\n                          include_top=include_top, input_shape=input_shape,\n                          pooling=pooling, classes=classes,\n                          **kwargs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = EfficientNetB3(include_top=True,\n                   input_shape=(2, 1025),\n                   pooling='max',\n                   classes=441)\nmodel.summary()\n%%time\n\n# NOTE:\n# Increase number if epochs from  1 to 60 or 100 for higher prediction accuracy\n# default is set to 1 for faster commit \nMAX_EPOCHS=100\nMAX_BATCH_SIZE=48            \n# learning rate reduction rate \nMAX_PATIENT=10\n\n# saved model checkpoint file\nbest_model_file=\"./best_model_trained.hdf5\"\n\n# callbacks\n# removed EarlyStopping(patience=MAX_PATIENT)\ncallback=[ReduceLROnPlateau(patience=MAX_PATIENT, verbose=1),\n          EarlyStopping(monitor='loss', mode='max', verbose=1, patience=50),\n          ModelCheckpoint(filepath=best_model_file, monitor='loss', verbose=1, save_best_only=True)]\n\n#compile\nmodel.compile(optimizer=\"Adam\",loss=\"mean_squared_error\",metrics=['accuracy', 'mean_squared_error'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = load_model('/kaggle/input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_stft_files = []\ntransform_files = []\npath = '/kaggle/input'\n\nif len(audio_stft_files)==len(transform_files): data = list(zip(audio_stft_files, transfrom_files))\nfor a_file, t_file in data:\n    audio = np.load(os.path.join(path, a_file)\n    transform = np.load(os.path.join(path, t_file)\n    print(audio.shape, transform.shape)\n                        \n                        \n                        \n    X_train, X_val, y_train, y_val = train_test_split(audio, transform, test_size=0.30, random_state=42)\n    print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n    \n                        \n    #train\n    print('training started.... please wait!')\n    history = model.fit(x=X_train, y=y_train,\n                        epochs=MAX_EPOCHS,\n                        batch_size=MAX_BATCH_SIZE, \n                        verbose=1,\n                        validation_data= (X_val, y_val), \n                        callbacks=callback)\n    print('training finished')\n\n    # # quick evaludate model\n    # print('Evaluate model with test data')\n    # score = model.evaluate(x=X_test,y=y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# %%memit\n\nimport matplotlib.pyplot as plt\n#Plot loss and accuracy for the training and validation set.\ndef plot_history(history):\n    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n    if len(loss_list) == 0:\n        print('Loss is missing in history')\n        return \n    plt.figure(figsize=(22,10))\n    ## As loss always exists\n    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n    ## Accuracy\n    plt.figure(221, figsize=(20,10))\n    ## Accuracy\n    # plt.figure(2,figsize=(14,5))\n    plt.subplot(221, title='Accuracy')\n    for l in acc_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n    for l in val_acc_list:    \n        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    ## Loss\n    plt.subplot(222, title='Loss')\n    for l in loss_list:\n        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n    for l in val_loss_list:\n        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))    \n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n# plot history\nplot_history(history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}